{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC5nKveq8Sh2"
      },
      "source": [
        "!kill -9  -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyRMPyIC1L3d"
      },
      "source": [
        "!pip uninstall keras\n",
        "!pip install keras==2.1.5\n",
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow==1.15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmRgOiIXo6JR"
      },
      "source": [
        "!git clone https://github.com/pythonlessons/OIDv4_ToolKit.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99cr91zOBzYw"
      },
      "source": [
        "!pip install awscli\n",
        "!pip install urllib3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GK1aWAn_yOHx"
      },
      "source": [
        "!python /content/OIDv4_ToolKit/main.py downloader --classes  Car Bus --type_csv train --limit 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtHo9jBZ0EC_"
      },
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "# from sys import exits\n",
        "import argparse\n",
        "import cv2\n",
        "from textwrap import dedent\n",
        "from lxml import etree\n",
        "\n",
        "XML_DIR = ''\n",
        "\n",
        "#os.chdir('Dataset')\n",
        "os.chdir(os.path.join(\"/content/OID/\", \"Dataset\"))\n",
        "DIRS = os.listdir(os.getcwd())\n",
        "\n",
        "for DIR in DIRS:\n",
        "    if os.path.isdir(DIR):\n",
        "        os.chdir(DIR)\n",
        "\n",
        "        print(\"Currently in Subdirectory:\", DIR)\n",
        "        CLASS_DIRS = os.listdir(os.getcwd()) \n",
        "        for CLASS_DIR in CLASS_DIRS:\n",
        "            if \" \" in CLASS_DIR:\n",
        "                os.rename(CLASS_DIR, CLASS_DIR.replace(\" \", \"_\"))\n",
        "        \n",
        "        CLASS_DIRS = os.listdir(os.getcwd())\n",
        "        for CLASS_DIR in CLASS_DIRS:\n",
        "            #if \" \" in CLASS_DIR:\n",
        "            #    os.rename(CLASS_DIR, CLASS_DIR.replace(\" \", \"_\"))\n",
        "            if os.path.isdir(CLASS_DIR):\n",
        "                os.chdir(CLASS_DIR)\n",
        "\n",
        "                print(\"\\n\" + \"Creating PASCAL VOC XML Files for Class:\", CLASS_DIR)\n",
        "                # Create Directory for annotations if it does not exist yet\n",
        "                #if not os.path.exists(XML_DIR):\n",
        "                #    os.makedirs(XML_DIR)\n",
        "\n",
        "                #Read Labels from OIDv4 ToolKit\n",
        "                os.chdir(\"Label\")\n",
        "\n",
        "                #Create PASCAL XML\n",
        "                for filename in tqdm(os.listdir(os.getcwd())):\n",
        "                    if filename.endswith(\".txt\"):\n",
        "                        filename_str = str.split(filename, \".\")[0]\n",
        "\n",
        "\n",
        "                        annotation = etree.Element(\"annotation\")\n",
        "                        \n",
        "                        os.chdir(\"..\")\n",
        "                        folder = etree.Element(\"folder\")\n",
        "                        folder.text = os.path.basename(os.getcwd())\n",
        "                        annotation.append(folder)\n",
        "\n",
        "                        filename_xml = etree.Element(\"filename\")\n",
        "                        filename_xml.text = filename_str + \".jpg\"\n",
        "                        annotation.append(filename_xml)\n",
        "\n",
        "                        path = etree.Element(\"path\")\n",
        "                        path.text = os.path.join(os.path.dirname(os.path.abspath(filename)), filename_str + \".jpg\")\n",
        "                        annotation.append(path)\n",
        "\n",
        "                        source = etree.Element(\"source\")\n",
        "                        annotation.append(source)\n",
        "\n",
        "                        database = etree.Element(\"database\")\n",
        "                        database.text = \"Unknown\"\n",
        "                        source.append(database)\n",
        "\n",
        "                        size = etree.Element(\"size\")\n",
        "                        annotation.append(size)\n",
        "\n",
        "                        width = etree.Element(\"width\")\n",
        "                        height = etree.Element(\"height\")\n",
        "                        depth = etree.Element(\"depth\")\n",
        "\n",
        "                        img = cv2.imread(filename_xml.text)\n",
        "\n",
        "                        try:\n",
        "                            width.text = str(img.shape[1])\n",
        "                        except AttributeError:\n",
        "                            #os.chdir(\"..\")\n",
        "                            os.chdir(\"Label\")\n",
        "                            continue\n",
        "                        height.text = str(img.shape[0])\n",
        "                        depth.text = str(img.shape[2])\n",
        "\n",
        "                        size.append(width)\n",
        "                        size.append(height)\n",
        "                        size.append(depth)\n",
        "\n",
        "                        segmented = etree.Element(\"segmented\")\n",
        "                        segmented.text = \"0\"\n",
        "                        annotation.append(segmented)\n",
        "\n",
        "                        os.chdir(\"Label\")\n",
        "                        label_original = open(filename, 'r')\n",
        "\n",
        "                        # Labels from OIDv4 Toolkit: name_of_class X_min Y_min X_max Y_max\n",
        "                        for line in label_original:\n",
        "                            line = line.strip()\n",
        "                            l = line.split(' ')\n",
        "                            class_name = l[0]\n",
        "                            try:\n",
        "                                xmin_l = str(int(float(l[1])))\n",
        "                                add1 = 0\n",
        "                            except ValueError:\n",
        "                                class_name = l[0]+\"_\"+l[1]\n",
        "                                add1 = 1\n",
        "\n",
        "                            xmin_l = str(int(float(l[1+add1])))\n",
        "                            ymin_l = str(int(float(l[2+add1])))\n",
        "                            xmax_l = str(int(float(l[3+add1])))\n",
        "                            ymax_l = str(int(float(l[4+add1])))\n",
        "                            \n",
        "                            obj = etree.Element(\"object\")\n",
        "                            annotation.append(obj)\n",
        "\n",
        "                            name = etree.Element(\"name\")\n",
        "                            name.text = class_name\n",
        "                            obj.append(name)\n",
        "\n",
        "                            pose = etree.Element(\"pose\")\n",
        "                            pose.text = \"Unspecified\"\n",
        "                            obj.append(pose)\n",
        "\n",
        "                            truncated = etree.Element(\"truncated\")\n",
        "                            truncated.text = \"0\"\n",
        "                            obj.append(truncated)\n",
        "\n",
        "                            difficult = etree.Element(\"difficult\")\n",
        "                            difficult.text = \"0\"\n",
        "                            obj.append(difficult)\n",
        "\n",
        "                            bndbox = etree.Element(\"bndbox\")\n",
        "                            obj.append(bndbox)\n",
        "\n",
        "                            xmin = etree.Element(\"xmin\")\n",
        "                            xmin.text = xmin_l\n",
        "                            bndbox.append(xmin)\n",
        "\n",
        "                            ymin = etree.Element(\"ymin\")\n",
        "                            ymin.text = ymin_l\n",
        "                            bndbox.append(ymin)\n",
        "\n",
        "                            xmax = etree.Element(\"xmax\")\n",
        "                            xmax.text = xmax_l\n",
        "                            bndbox.append(xmax)\n",
        "\n",
        "                            ymax = etree.Element(\"ymax\")\n",
        "                            ymax.text = ymax_l\n",
        "                            bndbox.append(ymax)\n",
        "\n",
        "                        os.chdir(\"..\")\n",
        "\n",
        "                        #os.chdir(XML_DIR)\n",
        "\n",
        "                        # write xml to file\n",
        "                        s = etree.tostring(annotation, pretty_print=True)\n",
        "                        with open(filename_str + \".xml\", 'wb') as f:\n",
        "                            f.write(s)\n",
        "                            f.close()\n",
        "\n",
        "                        #os.chdir(\"..\")\n",
        "                        os.chdir(\"Label\")\n",
        "\n",
        "                os.chdir(\"..\")\n",
        "                os.chdir(\"..\")   \n",
        "                   \n",
        "        os.chdir(\"..\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pLJBmU00D3g"
      },
      "source": [
        "# voc_to_YOLOv3.py\n",
        "import xml.etree.ElementTree as ET\n",
        "from os import getcwd\n",
        "import os\n",
        "\n",
        "\n",
        "dataset_train = '/content/OID/Dataset/train/'\n",
        "dataset_file = '4_CLASS_test.txt'\n",
        "classes_file = dataset_file[:-4]+'_classes.txt'\n",
        "\n",
        "\n",
        "CLS = os.listdir(dataset_train)\n",
        "classes =[dataset_train+CLASS for CLASS in CLS]\n",
        "# wd = getcwd()\n",
        "\n",
        "\n",
        "def test(fullname):\n",
        "    bb = \"\"\n",
        "    in_file = open(fullname)\n",
        "    tree=ET.parse(in_file)\n",
        "    root = tree.getroot()\n",
        "    for i, obj in enumerate(root.iter('object')):\n",
        "        difficult = obj.find('difficult').text\n",
        "        cls = obj.find('name').text\n",
        "        # print(\"aCLLLLLLSSSSS\",cls)\n",
        "        if cls not in CLS or int(difficult)==1:\n",
        "           \n",
        "            continue\n",
        "        cls_id = CLS.index(cls)\n",
        "        xmlbox = obj.find('bndbox')\n",
        "        b = (int(xmlbox.find('xmin').text), int(xmlbox.find('ymin').text), int(xmlbox.find('xmax').text), int(xmlbox.find('ymax').text))\n",
        "        bb += (\" \" + \",\".join([str(a) for a in b]) + ',' + str(cls_id))\n",
        "\n",
        "        # we need this because I don't know overlapping or something like that\n",
        "        # print(\"CLLLLLLSSSSS\",cls)\n",
        "        if cls == 'Traffic_light':\n",
        "            list_file = open(dataset_file, 'a')\n",
        "            file_string = str(fullname)[:-4]+'.jpg'+bb+'\\n'\n",
        "            print(\"file_string\",file_string)\n",
        "            list_file.write(file_string)\n",
        "            list_file.close()\n",
        "            bb = \"\"\n",
        "\n",
        "    if bb != \"\":\n",
        "        list_file = open(dataset_file, 'a')\n",
        "        file_string = str(fullname)[:-4]+'.jpg'+bb+'\\n'\n",
        "        list_file.write(file_string)\n",
        "        list_file.close()\n",
        "\n",
        "\n",
        "\n",
        "for CLASS in classes:\n",
        "    for filename in os.listdir(CLASS):\n",
        "        if not filename.endswith('.xml'):\n",
        "            continue\n",
        "        fullname = CLASS+'/'+filename\n",
        "        test(fullname)\n",
        "\n",
        "for CLASS in CLS:\n",
        "    list_file = open(classes_file, 'a')\n",
        "    file_string = str(CLASS)+\"\\n\"\n",
        "    list_file.write(file_string)\n",
        "    list_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcAx8bDt6Yhz"
      },
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XT_zR4YVOhte"
      },
      "source": [
        "!git clone https://github.com/pythonlessons/YOLOv3-object-detection-tutorial.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffETbGDnRK4c"
      },
      "source": [
        "cd /content/YOLOv3-object-detection-tutorial/YOLOv3-custom-training/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE9LXAK9yTSg"
      },
      "source": [
        "run convert.py model_data/yolov3.cfg model_data/yolov3.weights model_data/yolo_weights.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeQBTyhJ6wze"
      },
      "source": [
        "\"\"\"\n",
        "Retrain the YOLO model for your own dataset.\n",
        "\"\"\"\n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "\n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "from keras.layers import Input, Lambda\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n",
        "from yolo3.utils import get_random_data\n",
        "\n",
        "\n",
        "def _main():\n",
        "    annotation_path = '/content/OID/Dataset/4_CLASS_test.txt' ############################Change annotation_path to your file\n",
        "    log_dir = 'logs/000/' ################3Change log_dir, directory where to save trained model and checkpoints.\n",
        "    classes_path = '/content/OID/Dataset/4_CLASS_test_classes.txt'##########3 Change classes_path to your classes file \n",
        "    anchors_path = 'model_data/yolo_anchors.txt'##########anchors_path, don't change this if you don't know what you are doing.\n",
        "    class_names = get_classes(classes_path)\n",
        "    num_classes = len(class_names)\n",
        "    anchors = get_anchors(anchors_path)\n",
        "\n",
        "    input_shape = (416,416) # multiple of 32, hw\n",
        "\n",
        "    is_tiny_version = len(anchors)==6 # default setting\n",
        "    if is_tiny_version:\n",
        "        model = create_tiny_model(input_shape, anchors, num_classes,\n",
        "            freeze_body=2, weights_path='model_data/yolo_weights.h5')\n",
        "    else:\n",
        "        model = create_model(input_shape, anchors, num_classes, freeze_body=2, weights_path='model_data/yolo_weights.h5') # make sure you know what you freeze ######### If training new model, leave it as it is \"weights_path='model_data/yolo_weights.h5'\", otherwise link your checkpoint.\n",
        "\n",
        "\n",
        "    logging = TensorBoard(log_dir=log_dir)\n",
        "    checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
        "        monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
        "\n",
        "    val_split = 0.1\n",
        "    with open(annotation_path) as f:\n",
        "        lines = f.readlines()\n",
        "    np.random.shuffle(lines)\n",
        "    num_val = int(len(lines)*val_split)\n",
        "    num_train = len(lines) - num_val\n",
        "\n",
        "    # Train with frozen layers first, to get a stable loss.\n",
        "    # Adjust num epochs to your dataset. This step is enough to obtain a not bad model.\n",
        "    if True:\n",
        "        model.compile(optimizer=Adam(lr=1e-3), loss={\n",
        "            # use custom yolo_loss Lambda layer.\n",
        "            'yolo_loss': lambda y_true, y_pred: y_pred})\n",
        "\n",
        "        batch_size = 32 ####################### try to train with this, if you receive some kind of memory error, decrease this number\n",
        "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
        "        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
        "                steps_per_epoch=max(1, num_train//batch_size),\n",
        "                validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
        "                validation_steps=max(1, num_val//batch_size),\n",
        "                epochs=1,\n",
        "                initial_epoch=0,\n",
        "                callbacks=[logging, checkpoint])\n",
        "        model.save_weights(log_dir + 'trained_weights_stage_1.h5')\n",
        "\n",
        "    # Unfreeze and continue training, to fine-tune.\n",
        "    # Train longer if the result is not good.\n",
        "    if False:\n",
        "        for i in range(len(model.layers)):\n",
        "            model.layers[i].trainable = True\n",
        "        model.compile(optimizer=Adam(lr=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # recompile to apply the change\n",
        "        print('Unfreeze all of the layers.')\n",
        "\n",
        "        batch_size = 8 # note that more GPU memory is required after unfreezing the body ########try to train with this, if you receive some kind of memory error, decrease this number\n",
        "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
        "        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
        "            steps_per_epoch=max(1, num_train//batch_size),\n",
        "            validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
        "            validation_steps=max(1, num_val//batch_size),\n",
        "            epochs=100,\n",
        "            initial_epoch=50,\n",
        "            callbacks=[logging, checkpoint, reduce_lr, early_stopping])\n",
        "        model.save_weights(log_dir + 'trained_weights_final.h5')\n",
        "\n",
        "    # Further training if needed.\n",
        "\n",
        "\n",
        "def get_classes(classes_path):\n",
        "    '''loads the classes'''\n",
        "    with open(classes_path) as f:\n",
        "        class_names = f.readlines()\n",
        "    class_names = [c.strip() for c in class_names]\n",
        "    return class_names\n",
        "\n",
        "def get_anchors(anchors_path):\n",
        "    '''loads the anchors from a file'''\n",
        "    with open(anchors_path) as f:\n",
        "        anchors = f.readline()\n",
        "    anchors = [float(x) for x in anchors.split(',')]\n",
        "    return np.array(anchors).reshape(-1, 2)\n",
        "\n",
        "\n",
        "def create_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
        "            weights_path='model_data/yolo_weights.h5'):\n",
        "    '''create the training model'''\n",
        "    K.clear_session() # get a new session\n",
        "    image_input = Input(shape=(None, None, 3))\n",
        "    h, w = input_shape\n",
        "    num_anchors = len(anchors)\n",
        "\n",
        "    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n",
        "        num_anchors//3, num_classes+5)) for l in range(3)]\n",
        "\n",
        "    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n",
        "    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
        "\n",
        "    if load_pretrained:\n",
        "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
        "        print('Load weights {}.'.format(weights_path))\n",
        "        if freeze_body in [1, 2]:\n",
        "            # Freeze darknet53 body or freeze all but 3 output layers.\n",
        "            num = (185, len(model_body.layers)-3)[freeze_body-1]\n",
        "            for i in range(num): model_body.layers[i].trainable = False\n",
        "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
        "\n",
        "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
        "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n",
        "        [*model_body.output, *y_true])\n",
        "    model = Model([model_body.input, *y_true], model_loss)\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_tiny_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
        "            weights_path='model_data/tiny_yolo_weights.h5'):\n",
        "    '''create the training model, for Tiny YOLOv3'''\n",
        "    K.clear_session() # get a new session\n",
        "    image_input = Input(shape=(None, None, 3))\n",
        "    h, w = input_shape\n",
        "    num_anchors = len(anchors)\n",
        "\n",
        "    y_true = [Input(shape=(h//{0:32, 1:16}[l], w//{0:32, 1:16}[l], \\\n",
        "        num_anchors//2, num_classes+5)) for l in range(2)]\n",
        "\n",
        "    model_body = tiny_yolo_body(image_input, num_anchors//2, num_classes)\n",
        "    print('Create Tiny YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
        "\n",
        "    if load_pretrained:\n",
        "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
        "        print('Load weights {}.'.format(weights_path))\n",
        "        if freeze_body in [1, 2]:\n",
        "            # Freeze the darknet body or freeze all but 2 output layers.\n",
        "            num = (20, len(model_body.layers)-2)[freeze_body-1]\n",
        "            for i in range(num): model_body.layers[i].trainable = False\n",
        "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
        "\n",
        "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
        "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.7})(\n",
        "        [*model_body.output, *y_true])\n",
        "    model = Model([model_body.input, *y_true], model_loss)\n",
        "\n",
        "    return model\n",
        "\n",
        "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
        "    '''data generator for fit_generator'''\n",
        "    n = len(annotation_lines)\n",
        "    i = 0\n",
        "    while True:\n",
        "        image_data = []\n",
        "        box_data = []\n",
        "        for b in range(batch_size):\n",
        "            if i==0:\n",
        "                np.random.shuffle(annotation_lines)\n",
        "            image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n",
        "            image_data.append(image)\n",
        "            box_data.append(box)\n",
        "            i = (i+1) % n\n",
        "        image_data = np.array(image_data)\n",
        "        box_data = np.array(box_data)\n",
        "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
        "        yield [image_data, *y_true], np.zeros(batch_size)\n",
        "\n",
        "def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
        "    n = len(annotation_lines)\n",
        "    if n==0 or batch_size<=0: return None\n",
        "    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypiB7pzM0mPt"
      },
      "source": [
        "_main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX4EPLPIyy9F"
      },
      "source": [
        "import colorsys\r\n",
        "import os\r\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\r\n",
        "import cv2\r\n",
        "\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "from keras import backend as K\r\n",
        "from keras.models import load_model\r\n",
        "from keras.layers import Input\r\n",
        "\r\n",
        "from yolo3.model import yolo_eval, yolo_body, tiny_yolo_body\r\n",
        "from yolo3.utils import image_preporcess\r\n",
        "\r\n",
        "class YOLO(object):\r\n",
        "    _defaults = {\r\n",
        "        \"model_path\": '/content/YOLOv3-object-detection-tutorial/YOLOv3-custom-training/logs/000/trained_weights_stage_1.h5',\r\n",
        "        \"anchors_path\": 'model_data/yolo_anchors.txt',\r\n",
        "        \"classes_path\": '/content/OID/Dataset/4_CLASS_test_classes.txt',\r\n",
        "        \"score\" : 0.3,\r\n",
        "        \"iou\" : 0.8,\r\n",
        "        \"model_image_size\" : (416, 416),\r\n",
        "        \"text_size\" : 3,\r\n",
        "    }\r\n",
        "\r\n",
        "    @classmethod\r\n",
        "    def get_defaults(cls, n):\r\n",
        "        if n in cls._defaults:\r\n",
        "            return cls._defaults[n]\r\n",
        "        else:\r\n",
        "            return \"Unrecognized attribute name '\" + n + \"'\"\r\n",
        "\r\n",
        "    def __init__(self, **kwargs):\r\n",
        "        self.__dict__.update(self._defaults) # set up default values\r\n",
        "        self.__dict__.update(kwargs) # and update with user overrides\r\n",
        "        self.class_names = self._get_class()\r\n",
        "        self.anchors = self._get_anchors()\r\n",
        "        self.sess = K.get_session()\r\n",
        "        self.boxes, self.scores, self.classes = self.generate()\r\n",
        "\r\n",
        "    def _get_class(self):\r\n",
        "        classes_path = os.path.expanduser(self.classes_path)\r\n",
        "        with open(classes_path) as f:\r\n",
        "            class_names = f.readlines()\r\n",
        "        class_names = [c.strip() for c in class_names]\r\n",
        "        return class_names\r\n",
        "\r\n",
        "    def _get_anchors(self):\r\n",
        "        anchors_path = os.path.expanduser(self.anchors_path)\r\n",
        "        with open(anchors_path) as f:\r\n",
        "            anchors = f.readline()\r\n",
        "        anchors = [float(x) for x in anchors.split(',')]\r\n",
        "        return np.array(anchors).reshape(-1, 2)\r\n",
        "\r\n",
        "    def generate(self):\r\n",
        "        model_path = os.path.expanduser(self.model_path)\r\n",
        "        assert model_path.endswith('.h5'), 'Keras model or weights must be a .h5 file.'\r\n",
        "\r\n",
        "        # Load model, or construct model and load weights.\r\n",
        "        num_anchors = len(self.anchors)\r\n",
        "        num_classes = len(self.class_names)\r\n",
        "        is_tiny_version = num_anchors==6 # default setting\r\n",
        "        try:\r\n",
        "            self.yolo_model = load_model(model_path, compile=False)\r\n",
        "        except:\r\n",
        "            self.yolo_model = tiny_yolo_body(Input(shape=(None,None,3)), num_anchors//2, num_classes) \\\r\n",
        "                if is_tiny_version else yolo_body(Input(shape=(None,None,3)), num_anchors//3, num_classes)\r\n",
        "            self.yolo_model.load_weights(self.model_path) # make sure model, anchors and classes match\r\n",
        "        else:\r\n",
        "            assert self.yolo_model.layers[-1].output_shape[-1] == \\\r\n",
        "                num_anchors/len(self.yolo_model.output) * (num_classes + 5), \\\r\n",
        "                'Mismatch between model and given anchor and class sizes'\r\n",
        "\r\n",
        "        print('{} model, anchors, and classes loaded.'.format(model_path))\r\n",
        "\r\n",
        "        # Generate colors for drawing bounding boxes.\r\n",
        "        hsv_tuples = [(x / len(self.class_names), 1., 1.)\r\n",
        "                      for x in range(len(self.class_names))]\r\n",
        "        self.colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\r\n",
        "        self.colors = list(\r\n",
        "            map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\r\n",
        "                self.colors))\r\n",
        "\r\n",
        "        np.random.shuffle(self.colors)  # Shuffle colors to decorrelate adjacent classes.\r\n",
        "\r\n",
        "        # Generate output tensor targets for filtered bounding boxes.\r\n",
        "        self.input_image_shape = K.placeholder(shape=(2, ))\r\n",
        "        boxes, scores, classes = yolo_eval(self.yolo_model.output, self.anchors,\r\n",
        "                len(self.class_names), self.input_image_shape,\r\n",
        "                score_threshold=self.score, iou_threshold=self.iou)\r\n",
        "        return boxes, scores, classes\r\n",
        "\r\n",
        "    def detect_image(self, image):\r\n",
        "        if self.model_image_size != (None, None):\r\n",
        "            assert self.model_image_size[0]%32 == 0, 'Multiples of 32 required'\r\n",
        "            assert self.model_image_size[1]%32 == 0, 'Multiples of 32 required'\r\n",
        "            boxed_image = image_preporcess(np.copy(image), tuple(reversed(self.model_image_size)))\r\n",
        "            image_data = boxed_image\r\n",
        "\r\n",
        "        out_boxes, out_scores, out_classes = self.sess.run(\r\n",
        "            [self.boxes, self.scores, self.classes],\r\n",
        "            feed_dict={\r\n",
        "                self.yolo_model.input: image_data,\r\n",
        "                self.input_image_shape: [image.shape[0], image.shape[1]],#[image.size[1], image.size[0]],\r\n",
        "                K.learning_phase(): 0\r\n",
        "            })\r\n",
        "\r\n",
        "        #print('Found {} boxes for {}'.format(len(out_boxes), 'img'))\r\n",
        "\r\n",
        "        thickness = (image.shape[0] + image.shape[1]) // 600\r\n",
        "        fontScale=1\r\n",
        "        ObjectsList = []\r\n",
        "        \r\n",
        "        for i, c in reversed(list(enumerate(out_classes))):\r\n",
        "            predicted_class = self.class_names[c]\r\n",
        "            box = out_boxes[i]\r\n",
        "            score = out_scores[i]\r\n",
        "\r\n",
        "            label = '{} {:.2f}'.format(predicted_class, score)\r\n",
        "            #label = '{}'.format(predicted_class)\r\n",
        "            scores = '{:.2f}'.format(score)\r\n",
        "\r\n",
        "            top, left, bottom, right = box\r\n",
        "            top = max(0, np.floor(top + 0.5).astype('int32'))\r\n",
        "            left = max(0, np.floor(left + 0.5).astype('int32'))\r\n",
        "            bottom = min(image.shape[0], np.floor(bottom + 0.5).astype('int32'))\r\n",
        "            right = min(image.shape[1], np.floor(right + 0.5).astype('int32'))\r\n",
        "\r\n",
        "            mid_h = (bottom-top)/2+top\r\n",
        "            mid_v = (right-left)/2+left\r\n",
        "\r\n",
        "            # put object rectangle\r\n",
        "            cv2.rectangle(image, (left, top), (right, bottom), self.colors[c], thickness)\r\n",
        "\r\n",
        "            # get text size\r\n",
        "            (test_width, text_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, thickness/self.text_size, 1)\r\n",
        "\r\n",
        "            # put text rectangle\r\n",
        "            cv2.rectangle(image, (left, top), (left + test_width, top - text_height - baseline), self.colors[c], thickness=cv2.FILLED)\r\n",
        "\r\n",
        "            # put text above rectangle\r\n",
        "            cv2.putText(image, label, (left, top-2), cv2.FONT_HERSHEY_SIMPLEX, thickness/self.text_size, (0, 0, 0), 1)\r\n",
        "\r\n",
        "            # add everything to list\r\n",
        "            ObjectsList.append([top, left, bottom, right, mid_v, mid_h, label, scores])\r\n",
        "\r\n",
        "        return image, ObjectsList\r\n",
        "\r\n",
        "    def close_session(self):\r\n",
        "        self.sess.close()\r\n",
        "\r\n",
        "    def detect_img(self, image):\r\n",
        "        image = cv2.imread(image, cv2.IMREAD_COLOR)\r\n",
        "        original_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\r\n",
        "        original_image_color = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\r\n",
        "        \r\n",
        "        r_image, ObjectsList = self.detect_image(original_image_color)\r\n",
        "        return r_image, ObjectsList"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tSzeUbtkSd-"
      },
      "source": [
        "yolo = YOLO()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjaxOyQMlRAb"
      },
      "source": [
        "image = '/content/OID/Dataset/train/Car/34baa0b0d2eba65c.jpg'\r\n",
        "r_image, ObjectsList = yolo.detect_img(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkEbqkYrsCV-"
      },
      "source": [
        "ObjectsList"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cE_N3mbfroVF"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\r\n",
        "cv2_imshow(r_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxAuwntKp7sb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1LhlXL70o-1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}